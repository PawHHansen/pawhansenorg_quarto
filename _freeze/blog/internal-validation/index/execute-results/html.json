{
  "hash": "bed7bb3290ef629f694d625b7917eaa9",
  "result": {
    "markdown": "---\ntitle: \"Posterior predictive checking: Comparing observed data to replicated datasets from the model\"\ndescription: \"How well does your model fit your data? Simulation has the answer.\"\nauthor: \"Paw Hansen\"\ndate: \"9/22/2023\"\nimage: \"featured.jpeg\"\ncategories: [statistical analysis]\neditor_options: \n  chunk_output_type: console\n---\n\n\nWhat's the problem?\n\nWhat are the basic assumptions of any statistical model? (measurement validity, functional form etc.)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Packages used in this post\"}\nlibrary(tidyverse)\nlibrary(broom.mixed)\nlibrary(MASS)\nlibrary(rstanarm)\nlibrary(bayesplot)\nlibrary(modelsummary)\n\ntheme_set(theme_minimal(base_size = 14))\n```\n:::\n\n\nLet's set up a basic model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"Animals\")\n\nanimals <- Animals |> \n  mutate(specie = rownames(Animals))\n\nrm(Animals)\n```\n:::\n\n\nFit a first (naive) model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanimals |> \n  ggplot(aes(body, brain)) +\n  geom_point() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanimals |> \n  ggplot(aes(body, brain)) +\n  geom_point() +\n  scale_x_log10() + \n  scale_y_log10() + \n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanimals <- \n  animals |> \n  mutate(brain_log = log(brain),\n         body_log = log(body))\n```\n:::\n\n\n\n### By hand \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_lm <- \n  lm(brain_log ~ body_log, data = animals)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(mod_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic    p.value\n  <chr>          <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)    2.55     0.413       6.18 0.00000153\n2 body_log       0.496    0.0782      6.35 0.00000102\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(mod_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic    p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>      <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.608         0.593  1.53      40.3 0.00000102     1  -50.6  107.  111.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\n\nanimals_aug <- \n  augment(mod_lm)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanimals_aug |> \n  ggplot(aes(.fitted, .std.resid)) + \n  geom_hline(yintercept = 0, color = \"grey50\", lty = \"dashed\") + \n  geom_point() + \n  labs(x = \"Predicted values\",\n       y = \"Residuals\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### The easy way: Use `rstanarm`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_stan <-\n  stan_glm(brain_log ~ body_log, \n           prior_intercept = normal(location = 0, scale = 1, autoscale = F),\n           prior = normal(location = 0, scale = 1, autoscale = F),\n           data = animals)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000102 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.02 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.065934 seconds (Warm-up)\nChain 1:                0.068123 seconds (Sampling)\nChain 1:                0.134057 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.3e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.083251 seconds (Warm-up)\nChain 2:                0.105649 seconds (Sampling)\nChain 2:                0.1889 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 3.1e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.108 seconds (Warm-up)\nChain 3:                0.070644 seconds (Sampling)\nChain 3:                0.178644 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.9e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.082429 seconds (Warm-up)\nChain 4:                0.088401 seconds (Sampling)\nChain 4:                0.17083 seconds (Total)\nChain 4: \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelsummary(mod_stan)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n```\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 2.178 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\"> body_log </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> 0.496 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 </td>\n   <td style=\"text-align:center;\"> 0.573 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Adj. </td>\n   <td style=\"text-align:center;\"> 0.508 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Log.Lik. </td>\n   <td style=\"text-align:center;\"> −52.307 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ELPD </td>\n   <td style=\"text-align:center;\"> −55.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ELPD s.e. </td>\n   <td style=\"text-align:center;\"> 3.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LOOIC </td>\n   <td style=\"text-align:center;\"> 110.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LOOIC s.e. </td>\n   <td style=\"text-align:center;\"> 6.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WAIC </td>\n   <td style=\"text-align:center;\"> 109.9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 1.52 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ny_rep <- posterior_predict(mod_stan)\n```\n:::\n\n\nNow we can use some of the neat built-in functions to plot our replications and compare with the observed data.\n\nOne way would be to use histograms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Change plotting theme\ntheme_set(bayesplot::theme_default(base_family = \"sans\"))\n\nppc_hist(animals$brain_log, y_rep[1:19, ])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nOr we could use density curves and make a \"spaghetti plot\":\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppc_dens_overlay(animals$brain_log, y_rep[1:100, ]) + \n  scale_y_continuous(breaks=NULL)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWe can also use built-in functions to compute and visualize different test statistics. For example, let's make a histogram to plot the 25th percentile of the observed data against those of the replicated datasets:  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nppc_stat(animals$brain_log, y_rep, stat = function(y) quantile(y, 0.25))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nOr we could plot the standard deviation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppc_stat(animals$brain_log, y_rep, stat = function(y) sd(y))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Standard deviation ...](index_files/figure-html/fig-std-1.png){#fig-std width=672}\n:::\n:::\n\n\nIn both cases, this does not provide that much new information. The mean, mode and median of our replicated datasets are systematically lower than those in the observed data; indicating that there is some room for improvement in our model. \n\n### Final thoughts: Using simulation for design analysis\n\n-\n\n### Cool! Where can I learn more?\n\n-   Gelman, Hill, and Vehtari. (2020). *Regression and Other Stories*. Cambridge University Press.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}