{
  "hash": "03ec08961211429de7f1e019d49382a7",
  "result": {
    "markdown": "---\ntitle: \"Using simulation for design analysis part II: Iterating over multiple values\"\ndescription: \"Analyze the properties of your design, varying multiple features at once.\"\nauthor: \"Paw Hansen\"\ndate: \"9/12/2023\"\nimage: \"featured.jpeg\"\ncategories: [statistical analysis]\neditor_options: \n  chunk_output_type: console\n---\n\n\nIn my [previous post](https://www.pawhansen.org/blog/simulation-design-analysis/), I showed how you can use simulation to study the properties of different design choices.  \n\nIn this follow-up post, we'll expand on those ideas a bit by writing code that will allow us to study several features of the design at once. That is, we'll simulate data; varying both the number of subjects _and_ the treatment effect size. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Packages used in this post\"}\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(scales)\nlibrary(modelsummary)\n\ntheme_set(theme_minimal(base_size = 14))\n```\n:::\n\n\nWe begin with the same function as in my previous post. This will simulate _one_ dataset based on the number of subjects and treatment effect size you provide:  \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nsim_my_data <- function(n_subjects = NULL, treat_effect = NULL) {\n  \n  y_if_control <- rnorm(n_subjects, 60, 20)\n  y_if_treatment <- y_if_control + treat_effect\n  \n  tibble(\n    condition = sample(x = rep(c(\"Control\", \"Treated\"), n_subjects/2), \n                     size = n_subjects, \n                     replace = TRUE),\n    outcome = ifelse(condition == \"Control\", y_if_control, y_if_treatment)\n  )\n}\n```\n:::\n\n\n### Iterating over multilple features at once\n\nNow we can iterate that function over several different input values. Let's say we wanted to study the propteries of our design across the following: \n\n* number of subjects: 25, 50, 100, 250, 400\n* treatment effect sizes: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, and 10.\n\nThen, using `map2()` from the `purrr` packages, the code would look something like this:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nset.seed(1409)\n\ndat <- \n  crossing(\n  trial = 1:500,\n  n_subjects = c(25, 50, 100, 250, 400),\n  treat_effect = seq(0, 10, by = 1)\n  ) |> \n  mutate(\n    fake_dat = map2(.x = n_subjects, \n                    .y = treat_effect,\n                    .f = sim_my_data)\n  )\n```\n:::\n\n\nNotice that it takes some time to run - we're producing 55,000 datasets! If you're short on time, one option would be to use parallel processing.\n\nWith our simulations, we can fit a model to each simulated dataset before using `tidy()` to extract the information we need:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndat <- \n  dat |> \n    mutate(model = map(fake_dat, ~lm(outcome ~ condition, data =.)),\n           tidied = map(model, tidy))\n```\n:::\n\n\nFinally, we'll unnest the tidied results so that we can work with them: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ndat <- \n  dat |> \n  unnest(.cols = tidied)\n```\n:::\n\n\n### Using the simulations to study the proporties of different design features\n\nNow we are ready to interrogate our design. \n\nLet us use our simulations to calculate the power associated with different numbers of subjects _and_ different treatment effects sizes.  \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npower_rs <- \n  dat |> \n  group_by(n_subjects, treat_effect) |> \n  summarize(power = mean(p.value <= 0.05))\n\npower_rs \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 55 × 3\n# Groups:   n_subjects [5]\n   n_subjects treat_effect power\n        <dbl>        <dbl> <dbl>\n 1         25            0 0.521\n 2         25            1 0.524\n 3         25            2 0.533\n 4         25            3 0.527\n 5         25            4 0.539\n 6         25            5 0.536\n 7         25            6 0.551\n 8         25            7 0.561\n 9         25            8 0.58 \n10         25            9 0.573\n# ℹ 45 more rows\n```\n:::\n:::\n\n\nAnd let's make a plot to see how things behave: \n\n\n::: {.cell}\n\n```{.r .cell-code}\npower_rs |> \n  mutate(n_subjects = as.factor(n_subjects)) |> \n  ggplot(aes(treat_effect, power)) +\n  geom_line(aes(color = n_subjects)) +\n  scale_color_brewer(palette = \"Set1\") + \n  scale_y_continuous(labels = percent_format()) + \n  labs(x = \"Potential treatment effects\",\n       y = \"Statistical power\",\n       color = \"Number of subjects\") + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![Statistical power for different potential designs, varying both the treatment effect and the number of participating subjects.](index_files/figure-html/fig-power-1.png){#fig-power width=672}\n:::\n:::\n\n\nWe could also compute the standard error of the treatment effects to analyze its variation:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nrs <-\n  dat |> \n  filter(term == \"conditionTreated\") |> \n  group_by(n_subjects, treat_effect) |> \n  summarize(error = mean(std.error))\n\nrs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 55 × 3\n# Groups:   n_subjects [5]\n   n_subjects treat_effect error\n        <dbl>        <dbl> <dbl>\n 1         25            0  8.12\n 2         25            1  8.07\n 3         25            2  8.01\n 4         25            3  8.09\n 5         25            4  8.11\n 6         25            5  8.01\n 7         25            6  8.04\n 8         25            7  8.10\n 9         25            8  8.16\n10         25            9  8.16\n# ℹ 45 more rows\n```\n:::\n:::\n\n\nThere is a clear advantage of increasing n but the simulation also reminds us that the standard error does not depend on the treatment effect _size_:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrs |> \n  mutate(n_subjects = as.factor(n_subjects)) |> \n  ggplot(aes(treat_effect, error)) +\n  geom_line(aes(color = n_subjects)) +\n  scale_color_brewer(palette = \"Set1\") + \n  labs(x = \"Potential treatment effects\",\n       y = \"Standard error\",\n       color = \"Number of subjects\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![Standard effor of the treatment effect for different potential designs, varying both the treatment effect size and the number of participating subjects.](index_files/figure-html/fig-error-1.png){#fig-error width=672}\n:::\n:::\n\n\nFinal note: When wring up this post, I first tried to simulate data for the case of only 10 subjects. This caused issues with running the code, because with only 10 subjects there is a significant chance that in some of your simulations, all subjects will be either treatment or control. This is not just an annoyance but a useful reminder and a good example of how trying to simulate data will make you aware of issues you had not even considered. \n\n### Final thoughts: Using simulation for design analysis\n\nUsing simulation is incredibly useful for many things. In this post, I have shown you how you can use simulating to study how assumptions about e.g. the treatment effect will affect your conclusions as well as the consequences of making different design choices (e.g. increasing n). \n\n### Cool! Where can I learn more?\n\n-   Gelman, Hill, and Vehtari. (2020). *Regression and Other Stories*. Cambridge University Press.\n-   Alexander, R. (2023). *Telling Stories with Data: With Applications in R*. CRC Press.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}