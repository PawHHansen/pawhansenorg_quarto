{"title":"Bayesian analysis of a randomized controlled trial III: Interpretation and presentation","markdown":{"yaml":{"title":"Bayesian analysis of a randomized controlled trial III: Interpretation and presentation","description":"Final part of my three-part series on Bayesian analysis of randomized controlled trials. Get ready to interpret and present your results!","author":"Paw Hansen","date":"2023-07-13","image":"featured.jpg","categories":["Bayesian modeling","presentation"],"editor_options":{"chunk_output_type":"console"}},"headingText":"Analysis using `rstanarm`","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, warning = F, message = F)\n```\n\nWelcome to the last part of my three-part series on Bayesian analysis of randomized controlled trial. So far, we have specified priors to take previous knowledge into account and we have fit and validated two different models.\n\nIn this final post, we'll look at how we could go about presenting and interpreting our results. In a report or scientific article, this is the part that should go into the Results section.\n\n```{r packages}\n#| code-fold: true\n#| code-summary: \"Packages used in this post\"\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(tidybayes)\nlibrary(kableExtra)\n\ntheme_set(theme_minimal(base_size = 14))\n\n```\n\nIn my view, presenting results is where Bayesian analysis really gets to shine. As I hope you will see, taking a Bayesian approach makes it easy to present meaningful and intuitive quantities of interest and gives us incredible flexibility when it comes to answering question of real-world importance.\n\n```{r sim-fake, echo=FALSE, message=FALSE, warning=FALSE}\n\nset.seed(2023)\n\nfake <- \n  tibble(\n    condition = sample(c(0,1), 1000, replace = T),\n    noise = rnorm(1000, 0, 10), \n    true_ability = 50 + 2.5 * condition + noise, \n    fail_test = if_else(true_ability < 50, 1, 0)\n  ) |> \n  mutate(condition = ifelse(condition == 1, \"Treatment\", \n                            \"Control\")) |> \n  select(-c(true_ability, noise))\n\n```\n\nRecall that in our hypothetical experiment, students were randomly assigned to either a treatment or a control group. The outcome is dichotomous: did the students fail the reading test (indicating dyslexia) or not.\n\nBefore we go into any calculations, let's look at four core quantities of interest commonly used for controlled trial settings:\n\n-   absolute risk\n-   absolute risk reduction\n-   relative risk\n-   numbers needed to treat\n\nWhat do these numbers mean? The **absolute risk** is simply the risk of an event happening given the exposure. \n\n```{r}\n#| code-fold: false\nabs_risk <- \n  fake |> \n  summarize(abs_risk = mean(fail_test, na.rm = T), \n            .by = condition)\n\nabs_risk |> \n  mutate(across(where(is.numeric), ~round(., 2))) |> \n  kbl()\n```\n\nAt first sight, it seems the treatment worked! The absolute risk of failing the reading test was `r round(abs_risk$abs_risk[abs_risk$condition == \"Control\"], 2)` in the control group but only `r round(abs_risk$abs_risk[abs_risk$condition == \"Treatment\"], 2)` in the treatment group.\n\nSecond, the **absolute risk reduction** is the difference between the observed risks the treatment and the control group: \n\n```{r}\n#| code-fold: false\nround(abs_risk$abs_risk[abs_risk$condition == \"Control\"] \n      - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"], 2)\n```\n\nFor an individual, the risk reduction expresses the estimated difference in the probability of experiencing the event. In our case the reduction is `r round(abs_risk$abs_risk[abs_risk$condition == \"Control\"] - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"], 2) * 100` percent.\n\nThird, **relative risk** is the risk of an event occurring in the exposed group divided by the risk of the event occurring in the non-exposed group:\n\n```{r}\n#| code-fold: false\nround(abs_risk$abs_risk[abs_risk$condition == \"Treatment\"] \n      / abs_risk$abs_risk[abs_risk$condition == \"Control\"], 2)\n```\n\nThus, the **relative risk** of failing the reading test for students in the treatment group was only `r round(abs_risk$abs_risk[abs_risk$condition == \"Treatment\"] / abs_risk$abs_risk[abs_risk$condition == \"Control\"], 2)` as compared to students in the control group.\n\nNotice that the relative risk is _not_ the same as the odds, since the odds are the risk of an event occurring in any group divided by the risk of the event not occuring. \n\nFinally, the **number needed to treat** is the number of individuals you need to treat to prevent one additional bad outcome:\n\n```{r}\n#| code-fold: false\nround(1/ (abs_risk$abs_risk[abs_risk$condition == \"Control\"] \n          - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"]), 0)\n```\n\nFinally, for calculating the **number needed to treat**, we simply take 1 and divide it by the absolute risk reduction. Our results suggests that for every `r round(1/ (abs_risk$abs_risk[abs_risk$condition == \"Control\"] - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"]), 0)` students placed in the program, we could prevent 1 student from failing the reading test.\n\nHopefully, calculating each of these quantities \"by hand\", has given us some intuition about what each number conveys. In practice, though, we will never want to do it this way ever again. For one thing, the above approach did not give us any uncertainty estimates, which we should always include as part of any interpretation. Moreover, recalling formulas can be tedious and for more complicated models, many of these will break down anyway. Instead, we will use our posterior simulations.\n\n\n```{r model-evidence, echo=FALSE, warning=FALSE, message=FALSE}\n# Fit model\nmod_rstan <- \n  stan_glm(fail_test ~ condition, \n           family = \"binomial\",\n           prior_intercept = normal(0, 2.5),\n           prior = normal(0, 2.5), \n           data = fake, \n           refresh = 0)\n```\n\nThe core principle for presenting results is that we don't want to just show a list of model parameters. These have little interest in and off themselves. Instead, we'll use the model to make predictions, i.e. show the [*implications* of the model.](https://www.pawhansen.org/blog/2023-05-17-the-human-scale-principle-for-presenting-statistical-results/).\n\nTo this end, we set up a data frame containing the values of the predictors we intend to predict from (aka a \"predictor matrix\"). In our context of a controlled trial, these are simply the treatment and the control group:\n\n```{r stan-mod, warning=FALSE, message=FALSE}\n#| code-fold: false \npred_dat <- \n  crossing(\n    condition = c(\"Control\", \"Treatment\")\n    )\n\n```\n\nWe can then use this data frame to estimate the absolute risk for each group:\n\n```{r}\n#| code-fold: false\nmodel_preds <- \n  add_epred_draws(newdata = pred_dat, mod_rstan)\n```\n\nWith our predictions in place, we can plot distributions of each of the four quantities of interest, for example for including in a presentation. The following code chunk shows how to plot each of the four quantities from before:\n\n```{r}\n#| label: fig-qois\n#| layout-ncol: 2\n#| fig-cap: \"Quantities of interest with uncertainties, calculated using rstanarm.\"\n#| fig-subcap:\n#|   - \"Absolute risk of failing reading test.\"\n#|   - \"Relative risk of failing reading test when given treatment as opposed to control.\"\n#|   - \"Absolute risk reduction in failing reading test when given treatment\"\n#|   - \"Numbers needed to treat: How many students should be placed in the program to prevent one student from failing the reading test?\"\n  \n \n# abs risk of passing reading test\nmodel_preds |> \n  ggplot(aes(.epred, fill = condition)) + \n  geom_density(alpha = .4) + \n  annotate(geom = \"text\", x = .41, y = 2, label =\"Treatment\") + \n  annotate(geom = \"text\", x = .52, y = 2, label =\"Control\") + \n  scale_x_continuous(labels = scales::label_percent()) + \n  scale_y_continuous(labels = NULL) +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(x = \"Absolute risk\",\n       y = NULL, \n       fill = \"Condition\") + \n  theme(legend.position = \"none\")\n\n# rel risk of failing\nrel_risk <- \n  as_tibble(posterior_epred(mod_rstan, newdata = pred_dat)) |> \n  mutate(control = `1`, treatment = `2`) |> \n  mutate(relrisk = treatment / control) \n\nrel_risk |> \n  ggplot(aes(relrisk)) + \n  geom_histogram(fill = \"lightblue\", color = \"white\") + \n  geom_vline(xintercept = median(rel_risk$relrisk), \n             lty = 2,\n             color = \"firebrick\") + \n  scale_y_continuous(labels = NULL) +\n  labs(x = \"Relative risk\", \n       y = NULL)\n\n# abs risk reduction \nabs_rr <- \n  as_tibble(posterior_epred(mod_rstan, newdata = pred_dat)) |> \n  mutate(control = `1`, treatment = `2`) |> \n  mutate(abs_rr = control - treatment) \n\nabs_rr |> \n  ggplot(aes(abs_rr)) + \n  geom_histogram(fill = \"lightblue\", color = \"white\") +\n  geom_vline(xintercept = median(abs_rr$abs_rr), \n             lty = 2,\n             color = \"firebrick\") + \n  scale_y_continuous(labels = NULL) +\n  labs(x = \"Absoulte risk reduction\",\n       y = NULL)\n\n# Numbers needed to treat \nnntt <- \n  abs_rr |> \n  mutate(nn_treat = 1/abs_rr) \n\nnntt |> \n  ggplot(aes(nn_treat)) +\n  geom_histogram(fill = \"lightblue\", color = \"white\") +\n  geom_vline(xintercept = median(nntt$nn_treat), \n             lty = 2,\n             color = \"firebrick\") + \n  scale_y_continuous(labels = NULL) +\n  xlim(0, 25) + \n  labs(x = \"Numbers needed to treat\", \n       y = NULL)\n```\n\nWhen writing up our analysis, we could include one or more of these plots and then use the predictions to make meaningful statements about the model implications and uncertainties. Taking the number needed to treat as an example, we might want to calculate the 80 percent prediction interval:\n\n```{r}\nround(quantile(nntt$nn_treat, c(.1, .5, .9)))\n```\n\nFrom that, we could write something like: \"Using our Bayesian model, we estimated the number needed to treat. We found that the intervention should be applied to 9 students to prevent one case of dyslexia, plus or minus about 4 students.\"\n\n### Taking the posterior out for a spin: probability of a practically significant effect\n\nSo far we have covered most the standard quantities of interest for analyzing randomized controlled trials. But Bayesian analysis has more to offer.\n\nWhen working within a Bayesian framework, a lot of the hard work lies in specifying a sensible prior and then fitting a proper model. But once we have our posterior distribution(s) at hand, we can calculate *any* quantity that might be of interest.\n\nTo give a brief example, suppose a policy maker is only interested in scaling up the intervention if the absolute risk reduction is at least 15 percent (perhaps out of political or cost-effectiveness considerations).\n\nLooking at the histogram in @fig-qois-3, we see that *some* of the distribution is above .15. It is not impossible that the treatment effect *could* be .15 or more. But how *likely* is that? Put another way, given what we know (model, data), what is the probability that the absolute risk reduction is above 15 percent?\n\n```{r secret-dot, echo=FALSE, warning=FALSE, message=FALSE}\nsecret_dot <- \n  tibble(abs_rr = .15,\n         ecdf = 0.12675\n         )\n\nsecret_prob <- \n  round(mean(abs_rr$abs_rr > .15) * 100, 0)\n\n```\n\nWe can approach this graphically by drawing the **empirical cumulative distribution**, which shows the share of observations being lower than the specified value on the x-axis.\n\n```{r calc-densities, echo =FALSE,warning=FALSE, message=FALSE}\n\n# Calculate densities for each value of y/absolute risk ratio\nabs_rr_density_dens <- \n  density(abs_rr$abs_rr)\n\n# Store in a tibble with each value of x\nabs_rr_density_tibble <- \n  tibble(abs_rr = abs_rr_density_dens$x, \n         density = abs_rr_density_dens $y) |> \n  filter(abs_rr > .15)\n\n```\n\n@fig-post-sim-1 shows a distribution of plausible risk reductions given the data and model. The shaded region starting at 15 percent is what we care about. This region is an incredibly powerful concept because it allows us to think about effect sizes in terms of what _matters rather than what is \"statistically significant\".  \n\nWhat is the probability that our risk reduction lies within the ROPE? Figure @fig-post-sim-2, shows a so-called quantile function, plotting the potential risk reductions on the x-axis and the inverse cumulative probability on the y-axis. Substantially, the inverse cumulative probability describes the probability of the risk reduction being greater than the number on the x-axis. \n\nLooking at the figure, we see that the probability is about `r secret_prob`. Is this a lot or a little? Well, that depends... \n\nOf course `r secret_prob` percent, or about 1-in-8, does not sound like a lot. But suppose that running the intervention is really cheap. Then, policy makers may want to \"roll the dice\" and see what happens. After all, the probability that the effect size is greater than 15 percent is small, but the probability that the effect size is at least 5 percent is `r round(mean(abs_rr$abs_rr > .05) * 100, 0)` percent!\n\nThe point is that when doing Bayesian analysis, we do not bake decision-making into the analysis, such as saying that the treatment \"worked\" because _p_ happened to be <0.05. Instead, we live with the uncertainty; estimating the effect size and uncertainties the best we can, and then leave the rest up to stakeholders.  \n\n```{r}\n#| label: fig-post-sim\n#| layout-ncol: 2\n#| fig-cap: \"What is the probability that the risk reduction is above 15 percent?\"\n#| fig-subcap:\n#|   - \"Distribution of the plausable risk reductions given the data and model. Policy maker only cares about the blue area.\"\n#|   - \"Quantile fundction showing the distribution of plausable risk reductions. The graph shows the probability of the absoulute risk reduction being lower than the specified value on the x-axis.\"\n\n# Density curve \nabs_rr |> \n  ggplot(aes(abs_rr)) + \n  geom_density() + \n  geom_vline(xintercept = .15, \n             linetype = \"dashed\", \n             color = \"steelblue\") + \n  geom_area(data = abs_rr_density_tibble, \n            aes(x = abs_rr, y = density), \n            fill = \"lightblue\",\n            alpha = .4) + \n  scale_x_continuous(labels = scales::label_percent()) + \n  scale_y_continuous(labels = NULL) + \n  labs(x = \"Absolute risk reduction\",\n       y = NULL)\n\n# ECDF\nabs_rr |> \n  ggplot(aes(abs_rr)) +\n  geom_vline(xintercept = .15, color = \"steelblue\", linetype = \"dashed\") + \n  stat_ecdf(aes(y = 1 - ..y..)) + \n  geom_point(data = secret_dot, aes(abs_rr, ecdf), color = \"steelblue\") + \n  annotate(geom = \"text\", x = .21, y = .14, label = str_c(\"Pr(ARR > 15 pct.): \\n\", secret_prob, \" pct.\"), color = \"steelblue\", size = 4) + \n  scale_x_continuous(labels = scales::label_percent(),  limits = c(0, .25)) + \n  scale_y_continuous(labels = scales::label_percent()) + \n  labs(x = \"Absolute risk reduction\", \n       y = \"Inverse cumulative probability\")\n```\n\nOf course, in addition to eyeballing the graph, we can ask R to extract the exact probability for us:\n\n```{r calc-ecdf}\nmean(abs_rr$abs_rr > .15)\n```\n\nAs a final tip, interpreting a quantile function may be tricky to non-technical audiences. If I were advising, say, a politician, I might prefer to present some meaningful risk reductions and then simply present these in a small table such as @tbl-post-probs:\n\n```{r tbl-arr-prob, warning=FALSE, message=FALSE, echo=FALSE}\n#| label: tbl-post-probs\n#| tbl-cap: \"Posterior probabilities of various minimum effect sizes\"\n\ntibble(\n    rr = c(.05, .1, .15, .20),\n    prob = c(mean(abs_rr$abs_rr > .05),\n                      mean(abs_rr$abs_rr > .10),\n                      mean(abs_rr$abs_rr > .15), \n                      mean(abs_rr$abs_rr > .20)\n                      )\n    ) |> \n  kable(col.names = c(\"Minimum risk reduction\", \"Probability\"), \n    digits = 2) \n```\n\n### Final thoughts: Bayesian analysis of a randomized controlled trial - interpretation and presentation\n\nBayesian analysis has a lot to offer when conducting and interpreting statistical analyses of randomized controlled trials. It allows analysts to interpret results in a way that is usually far more intuitive and useful to policy makers than standard reports relying on statistical significance tests. Rather than discretizing results (the treatment either \"worked\" or \"failed\"), Bayesian analysis makes it possible to make more nuanced statements (\"the probability that the treatment effect is above the desired 15 percentage points is 97 percent\"). Taken together, I hope this post and the two previous ones in the three-part series has encouraged you to go and do your first Bayesian analysis!\n\n### Cool! Where can I learn more?\n\n-   Johnson, A. A., Ott, M. Q., & Dogucu, M. (2022). *Bayes rules!: An introduction to applied Bayesian modeling*. CRC Press.\n\n-   Gelman, A., Hill, J., & Vehtari, A. (2020). *Regression and other stories*. Cambridge University Press.\n\n-   Ryan, E. G., Harrison, E. M., Pearse, R. M., & Gates, S. (2019). Perioperative haemodynamic therapy for major gastrointestinal surgery: the effect of a Bayesian approach to interpreting the findings of a randomised controlled trial. *BMJ open, 9(3)*.\n\n-   Goodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). *rstanarm: Bayesian applied regression modeling via Stan*. Find many of their useful vignettes [here](https://mc-stan.org/rstanarm/).","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, warning = F, message = F)\n```\n\nWelcome to the last part of my three-part series on Bayesian analysis of randomized controlled trial. So far, we have specified priors to take previous knowledge into account and we have fit and validated two different models.\n\nIn this final post, we'll look at how we could go about presenting and interpreting our results. In a report or scientific article, this is the part that should go into the Results section.\n\n```{r packages}\n#| code-fold: true\n#| code-summary: \"Packages used in this post\"\n\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(tidybayes)\nlibrary(kableExtra)\n\ntheme_set(theme_minimal(base_size = 14))\n\n```\n\nIn my view, presenting results is where Bayesian analysis really gets to shine. As I hope you will see, taking a Bayesian approach makes it easy to present meaningful and intuitive quantities of interest and gives us incredible flexibility when it comes to answering question of real-world importance.\n\n```{r sim-fake, echo=FALSE, message=FALSE, warning=FALSE}\n\nset.seed(2023)\n\nfake <- \n  tibble(\n    condition = sample(c(0,1), 1000, replace = T),\n    noise = rnorm(1000, 0, 10), \n    true_ability = 50 + 2.5 * condition + noise, \n    fail_test = if_else(true_ability < 50, 1, 0)\n  ) |> \n  mutate(condition = ifelse(condition == 1, \"Treatment\", \n                            \"Control\")) |> \n  select(-c(true_ability, noise))\n\n```\n\nRecall that in our hypothetical experiment, students were randomly assigned to either a treatment or a control group. The outcome is dichotomous: did the students fail the reading test (indicating dyslexia) or not.\n\nBefore we go into any calculations, let's look at four core quantities of interest commonly used for controlled trial settings:\n\n-   absolute risk\n-   absolute risk reduction\n-   relative risk\n-   numbers needed to treat\n\nWhat do these numbers mean? The **absolute risk** is simply the risk of an event happening given the exposure. \n\n```{r}\n#| code-fold: false\nabs_risk <- \n  fake |> \n  summarize(abs_risk = mean(fail_test, na.rm = T), \n            .by = condition)\n\nabs_risk |> \n  mutate(across(where(is.numeric), ~round(., 2))) |> \n  kbl()\n```\n\nAt first sight, it seems the treatment worked! The absolute risk of failing the reading test was `r round(abs_risk$abs_risk[abs_risk$condition == \"Control\"], 2)` in the control group but only `r round(abs_risk$abs_risk[abs_risk$condition == \"Treatment\"], 2)` in the treatment group.\n\nSecond, the **absolute risk reduction** is the difference between the observed risks the treatment and the control group: \n\n```{r}\n#| code-fold: false\nround(abs_risk$abs_risk[abs_risk$condition == \"Control\"] \n      - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"], 2)\n```\n\nFor an individual, the risk reduction expresses the estimated difference in the probability of experiencing the event. In our case the reduction is `r round(abs_risk$abs_risk[abs_risk$condition == \"Control\"] - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"], 2) * 100` percent.\n\nThird, **relative risk** is the risk of an event occurring in the exposed group divided by the risk of the event occurring in the non-exposed group:\n\n```{r}\n#| code-fold: false\nround(abs_risk$abs_risk[abs_risk$condition == \"Treatment\"] \n      / abs_risk$abs_risk[abs_risk$condition == \"Control\"], 2)\n```\n\nThus, the **relative risk** of failing the reading test for students in the treatment group was only `r round(abs_risk$abs_risk[abs_risk$condition == \"Treatment\"] / abs_risk$abs_risk[abs_risk$condition == \"Control\"], 2)` as compared to students in the control group.\n\nNotice that the relative risk is _not_ the same as the odds, since the odds are the risk of an event occurring in any group divided by the risk of the event not occuring. \n\nFinally, the **number needed to treat** is the number of individuals you need to treat to prevent one additional bad outcome:\n\n```{r}\n#| code-fold: false\nround(1/ (abs_risk$abs_risk[abs_risk$condition == \"Control\"] \n          - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"]), 0)\n```\n\nFinally, for calculating the **number needed to treat**, we simply take 1 and divide it by the absolute risk reduction. Our results suggests that for every `r round(1/ (abs_risk$abs_risk[abs_risk$condition == \"Control\"] - abs_risk$abs_risk[abs_risk$condition == \"Treatment\"]), 0)` students placed in the program, we could prevent 1 student from failing the reading test.\n\nHopefully, calculating each of these quantities \"by hand\", has given us some intuition about what each number conveys. In practice, though, we will never want to do it this way ever again. For one thing, the above approach did not give us any uncertainty estimates, which we should always include as part of any interpretation. Moreover, recalling formulas can be tedious and for more complicated models, many of these will break down anyway. Instead, we will use our posterior simulations.\n\n### Analysis using `rstanarm`\n\n```{r model-evidence, echo=FALSE, warning=FALSE, message=FALSE}\n# Fit model\nmod_rstan <- \n  stan_glm(fail_test ~ condition, \n           family = \"binomial\",\n           prior_intercept = normal(0, 2.5),\n           prior = normal(0, 2.5), \n           data = fake, \n           refresh = 0)\n```\n\nThe core principle for presenting results is that we don't want to just show a list of model parameters. These have little interest in and off themselves. Instead, we'll use the model to make predictions, i.e. show the [*implications* of the model.](https://www.pawhansen.org/blog/2023-05-17-the-human-scale-principle-for-presenting-statistical-results/).\n\nTo this end, we set up a data frame containing the values of the predictors we intend to predict from (aka a \"predictor matrix\"). In our context of a controlled trial, these are simply the treatment and the control group:\n\n```{r stan-mod, warning=FALSE, message=FALSE}\n#| code-fold: false \npred_dat <- \n  crossing(\n    condition = c(\"Control\", \"Treatment\")\n    )\n\n```\n\nWe can then use this data frame to estimate the absolute risk for each group:\n\n```{r}\n#| code-fold: false\nmodel_preds <- \n  add_epred_draws(newdata = pred_dat, mod_rstan)\n```\n\nWith our predictions in place, we can plot distributions of each of the four quantities of interest, for example for including in a presentation. The following code chunk shows how to plot each of the four quantities from before:\n\n```{r}\n#| label: fig-qois\n#| layout-ncol: 2\n#| fig-cap: \"Quantities of interest with uncertainties, calculated using rstanarm.\"\n#| fig-subcap:\n#|   - \"Absolute risk of failing reading test.\"\n#|   - \"Relative risk of failing reading test when given treatment as opposed to control.\"\n#|   - \"Absolute risk reduction in failing reading test when given treatment\"\n#|   - \"Numbers needed to treat: How many students should be placed in the program to prevent one student from failing the reading test?\"\n  \n \n# abs risk of passing reading test\nmodel_preds |> \n  ggplot(aes(.epred, fill = condition)) + \n  geom_density(alpha = .4) + \n  annotate(geom = \"text\", x = .41, y = 2, label =\"Treatment\") + \n  annotate(geom = \"text\", x = .52, y = 2, label =\"Control\") + \n  scale_x_continuous(labels = scales::label_percent()) + \n  scale_y_continuous(labels = NULL) +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(x = \"Absolute risk\",\n       y = NULL, \n       fill = \"Condition\") + \n  theme(legend.position = \"none\")\n\n# rel risk of failing\nrel_risk <- \n  as_tibble(posterior_epred(mod_rstan, newdata = pred_dat)) |> \n  mutate(control = `1`, treatment = `2`) |> \n  mutate(relrisk = treatment / control) \n\nrel_risk |> \n  ggplot(aes(relrisk)) + \n  geom_histogram(fill = \"lightblue\", color = \"white\") + \n  geom_vline(xintercept = median(rel_risk$relrisk), \n             lty = 2,\n             color = \"firebrick\") + \n  scale_y_continuous(labels = NULL) +\n  labs(x = \"Relative risk\", \n       y = NULL)\n\n# abs risk reduction \nabs_rr <- \n  as_tibble(posterior_epred(mod_rstan, newdata = pred_dat)) |> \n  mutate(control = `1`, treatment = `2`) |> \n  mutate(abs_rr = control - treatment) \n\nabs_rr |> \n  ggplot(aes(abs_rr)) + \n  geom_histogram(fill = \"lightblue\", color = \"white\") +\n  geom_vline(xintercept = median(abs_rr$abs_rr), \n             lty = 2,\n             color = \"firebrick\") + \n  scale_y_continuous(labels = NULL) +\n  labs(x = \"Absoulte risk reduction\",\n       y = NULL)\n\n# Numbers needed to treat \nnntt <- \n  abs_rr |> \n  mutate(nn_treat = 1/abs_rr) \n\nnntt |> \n  ggplot(aes(nn_treat)) +\n  geom_histogram(fill = \"lightblue\", color = \"white\") +\n  geom_vline(xintercept = median(nntt$nn_treat), \n             lty = 2,\n             color = \"firebrick\") + \n  scale_y_continuous(labels = NULL) +\n  xlim(0, 25) + \n  labs(x = \"Numbers needed to treat\", \n       y = NULL)\n```\n\nWhen writing up our analysis, we could include one or more of these plots and then use the predictions to make meaningful statements about the model implications and uncertainties. Taking the number needed to treat as an example, we might want to calculate the 80 percent prediction interval:\n\n```{r}\nround(quantile(nntt$nn_treat, c(.1, .5, .9)))\n```\n\nFrom that, we could write something like: \"Using our Bayesian model, we estimated the number needed to treat. We found that the intervention should be applied to 9 students to prevent one case of dyslexia, plus or minus about 4 students.\"\n\n### Taking the posterior out for a spin: probability of a practically significant effect\n\nSo far we have covered most the standard quantities of interest for analyzing randomized controlled trials. But Bayesian analysis has more to offer.\n\nWhen working within a Bayesian framework, a lot of the hard work lies in specifying a sensible prior and then fitting a proper model. But once we have our posterior distribution(s) at hand, we can calculate *any* quantity that might be of interest.\n\nTo give a brief example, suppose a policy maker is only interested in scaling up the intervention if the absolute risk reduction is at least 15 percent (perhaps out of political or cost-effectiveness considerations).\n\nLooking at the histogram in @fig-qois-3, we see that *some* of the distribution is above .15. It is not impossible that the treatment effect *could* be .15 or more. But how *likely* is that? Put another way, given what we know (model, data), what is the probability that the absolute risk reduction is above 15 percent?\n\n```{r secret-dot, echo=FALSE, warning=FALSE, message=FALSE}\nsecret_dot <- \n  tibble(abs_rr = .15,\n         ecdf = 0.12675\n         )\n\nsecret_prob <- \n  round(mean(abs_rr$abs_rr > .15) * 100, 0)\n\n```\n\nWe can approach this graphically by drawing the **empirical cumulative distribution**, which shows the share of observations being lower than the specified value on the x-axis.\n\n```{r calc-densities, echo =FALSE,warning=FALSE, message=FALSE}\n\n# Calculate densities for each value of y/absolute risk ratio\nabs_rr_density_dens <- \n  density(abs_rr$abs_rr)\n\n# Store in a tibble with each value of x\nabs_rr_density_tibble <- \n  tibble(abs_rr = abs_rr_density_dens$x, \n         density = abs_rr_density_dens $y) |> \n  filter(abs_rr > .15)\n\n```\n\n@fig-post-sim-1 shows a distribution of plausible risk reductions given the data and model. The shaded region starting at 15 percent is what we care about. This region is an incredibly powerful concept because it allows us to think about effect sizes in terms of what _matters rather than what is \"statistically significant\".  \n\nWhat is the probability that our risk reduction lies within the ROPE? Figure @fig-post-sim-2, shows a so-called quantile function, plotting the potential risk reductions on the x-axis and the inverse cumulative probability on the y-axis. Substantially, the inverse cumulative probability describes the probability of the risk reduction being greater than the number on the x-axis. \n\nLooking at the figure, we see that the probability is about `r secret_prob`. Is this a lot or a little? Well, that depends... \n\nOf course `r secret_prob` percent, or about 1-in-8, does not sound like a lot. But suppose that running the intervention is really cheap. Then, policy makers may want to \"roll the dice\" and see what happens. After all, the probability that the effect size is greater than 15 percent is small, but the probability that the effect size is at least 5 percent is `r round(mean(abs_rr$abs_rr > .05) * 100, 0)` percent!\n\nThe point is that when doing Bayesian analysis, we do not bake decision-making into the analysis, such as saying that the treatment \"worked\" because _p_ happened to be <0.05. Instead, we live with the uncertainty; estimating the effect size and uncertainties the best we can, and then leave the rest up to stakeholders.  \n\n```{r}\n#| label: fig-post-sim\n#| layout-ncol: 2\n#| fig-cap: \"What is the probability that the risk reduction is above 15 percent?\"\n#| fig-subcap:\n#|   - \"Distribution of the plausable risk reductions given the data and model. Policy maker only cares about the blue area.\"\n#|   - \"Quantile fundction showing the distribution of plausable risk reductions. The graph shows the probability of the absoulute risk reduction being lower than the specified value on the x-axis.\"\n\n# Density curve \nabs_rr |> \n  ggplot(aes(abs_rr)) + \n  geom_density() + \n  geom_vline(xintercept = .15, \n             linetype = \"dashed\", \n             color = \"steelblue\") + \n  geom_area(data = abs_rr_density_tibble, \n            aes(x = abs_rr, y = density), \n            fill = \"lightblue\",\n            alpha = .4) + \n  scale_x_continuous(labels = scales::label_percent()) + \n  scale_y_continuous(labels = NULL) + \n  labs(x = \"Absolute risk reduction\",\n       y = NULL)\n\n# ECDF\nabs_rr |> \n  ggplot(aes(abs_rr)) +\n  geom_vline(xintercept = .15, color = \"steelblue\", linetype = \"dashed\") + \n  stat_ecdf(aes(y = 1 - ..y..)) + \n  geom_point(data = secret_dot, aes(abs_rr, ecdf), color = \"steelblue\") + \n  annotate(geom = \"text\", x = .21, y = .14, label = str_c(\"Pr(ARR > 15 pct.): \\n\", secret_prob, \" pct.\"), color = \"steelblue\", size = 4) + \n  scale_x_continuous(labels = scales::label_percent(),  limits = c(0, .25)) + \n  scale_y_continuous(labels = scales::label_percent()) + \n  labs(x = \"Absolute risk reduction\", \n       y = \"Inverse cumulative probability\")\n```\n\nOf course, in addition to eyeballing the graph, we can ask R to extract the exact probability for us:\n\n```{r calc-ecdf}\nmean(abs_rr$abs_rr > .15)\n```\n\nAs a final tip, interpreting a quantile function may be tricky to non-technical audiences. If I were advising, say, a politician, I might prefer to present some meaningful risk reductions and then simply present these in a small table such as @tbl-post-probs:\n\n```{r tbl-arr-prob, warning=FALSE, message=FALSE, echo=FALSE}\n#| label: tbl-post-probs\n#| tbl-cap: \"Posterior probabilities of various minimum effect sizes\"\n\ntibble(\n    rr = c(.05, .1, .15, .20),\n    prob = c(mean(abs_rr$abs_rr > .05),\n                      mean(abs_rr$abs_rr > .10),\n                      mean(abs_rr$abs_rr > .15), \n                      mean(abs_rr$abs_rr > .20)\n                      )\n    ) |> \n  kable(col.names = c(\"Minimum risk reduction\", \"Probability\"), \n    digits = 2) \n```\n\n### Final thoughts: Bayesian analysis of a randomized controlled trial - interpretation and presentation\n\nBayesian analysis has a lot to offer when conducting and interpreting statistical analyses of randomized controlled trials. It allows analysts to interpret results in a way that is usually far more intuitive and useful to policy makers than standard reports relying on statistical significance tests. Rather than discretizing results (the treatment either \"worked\" or \"failed\"), Bayesian analysis makes it possible to make more nuanced statements (\"the probability that the treatment effect is above the desired 15 percentage points is 97 percent\"). Taken together, I hope this post and the two previous ones in the three-part series has encouraged you to go and do your first Bayesian analysis!\n\n### Cool! Where can I learn more?\n\n-   Johnson, A. A., Ott, M. Q., & Dogucu, M. (2022). *Bayes rules!: An introduction to applied Bayesian modeling*. CRC Press.\n\n-   Gelman, A., Hill, J., & Vehtari, A. (2020). *Regression and other stories*. Cambridge University Press.\n\n-   Ryan, E. G., Harrison, E. M., Pearse, R. M., & Gates, S. (2019). Perioperative haemodynamic therapy for major gastrointestinal surgery: the effect of a Bayesian approach to interpreting the findings of a randomised controlled trial. *BMJ open, 9(3)*.\n\n-   Goodrich, B., Gabry, J., Ali, I., & Brilleman, S. (2020). *rstanarm: Bayesian applied regression modeling via Stan*. Find many of their useful vignettes [here](https://mc-stan.org/rstanarm/)."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","theme":{"light":["litera","../../custom.css"],"dark":["slate","custom.scss"]},"smooth-scroll":true,"title-block-banner":true,"title":"Bayesian analysis of a randomized controlled trial III: Interpretation and presentation","description":"Final part of my three-part series on Bayesian analysis of randomized controlled trials. Get ready to interpret and present your results!","author":"Paw Hansen","date":"2023-07-13","image":"featured.jpg","categories":["Bayesian modeling","presentation"],"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}